{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making FC Barcelona Face Recognition Model with VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# Setting the input size now to 64 x 64 pixel \n",
    "img_rows = 64\n",
    "img_cols = 64 \n",
    "\n",
    "# loads the VGG16 model without the top or FC layers\n",
    "vgg16 = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# Here we freeze the last 4 layers, i.e. include_top = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezing all the layers except the Top 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "# Layers are set to trainable as True by default\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(vgg16.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make a function that returns our FC Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barcaface(bottom_model, num_classes):\n",
    "  \"\"\"creates the top or head of the model that will be \n",
    "    placed on top of the bottom layers\"\"\"\n",
    "  top_model = bottom_model.output\n",
    "  top_model = Flatten(name = \"flatten\")(top_model)\n",
    "  top_model = Dense(512, activation='relu')(top_model)\n",
    "  top_model = Dense(256, activation='relu')(top_model)\n",
    "  top_model = Dense(128, activation='relu')(top_model)\n",
    "  top_model = Dense(num_classes, activation='softmax')(top_model)\n",
    "  return top_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's add our FC head back onto VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 15,928,387\n",
      "Trainable params: 1,213,699\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "    \n",
    "# Number of classes in the Flowers-17 dataset\n",
    "num_classes = 3\n",
    "\n",
    "FC_Head = barcaface(vgg16, num_classes)\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=FC_Head)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading our Barca Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 images belonging to 3 classes.\n",
      "Found 100 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir = 'Train/'\n",
    "validation_data_dir = 'Test/'\n",
    "\n",
    "# Augmenting the data!\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 16\n",
    "val_batchsize = 10\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=train_batchsize,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=val_batchsize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training out our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are using the concept of checkpoint and early stopping here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 123s 2s/step - loss: 1.0486 - accuracy: 0.4453 - val_loss: 1.0313 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03129, saving model to FCBarcelona_vgg16_64.h5\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 115s 2s/step - loss: 0.9435 - accuracy: 0.5668 - val_loss: 1.1568 - val_accuracy: 0.4700\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03129\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 113s 2s/step - loss: 0.8707 - accuracy: 0.6053 - val_loss: 0.6617 - val_accuracy: 0.4400\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03129 to 0.66174, saving model to FCBarcelona_vgg16_64.h5\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 112s 2s/step - loss: 0.8073 - accuracy: 0.6373 - val_loss: 0.7634 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.66174\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 102s 2s/step - loss: 0.7836 - accuracy: 0.6490 - val_loss: 0.5603 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66174 to 0.56033, saving model to FCBarcelona_vgg16_64.h5\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 105s 2s/step - loss: 0.6954 - accuracy: 0.7162 - val_loss: 0.3568 - val_accuracy: 0.4600\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56033 to 0.35683, saving model to FCBarcelona_vgg16_64.h5\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 105s 2s/step - loss: 0.6741 - accuracy: 0.7300 - val_loss: 0.6244 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35683\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 101s 2s/step - loss: 0.6193 - accuracy: 0.7540 - val_loss: 0.6764 - val_accuracy: 0.5100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.35683\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 101s 2s/step - loss: 0.6075 - accuracy: 0.7621 - val_loss: 0.5598 - val_accuracy: 0.4400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.35683\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 103s 2s/step - loss: 0.4983 - accuracy: 0.8197 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35683\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "                   \n",
    "checkpoint = ModelCheckpoint(\"FCBarcelona_vgg16_64.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 5,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.00001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]\n",
    "\n",
    "# Note we use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.0001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Enter the number of training and validation samples here\n",
    "nb_train_samples = 324\n",
    "nb_validation_samples = 100\n",
    "\n",
    "# We are only training 6 EPOCHS\n",
    "epochs = 10\n",
    "batch_size = 5\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = callbacks,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "\n",
    "# Saving our model\n",
    "model.save(\"FCBarcelona_vgg16_64.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('FCBarcelona_vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our classifier on some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - Gerard Pique\n",
      "Class - De Jong\n",
      "Class - Messi\n",
      "Class - Gerard Pique\n",
      "Class - Gerard Pique\n",
      "Class - De Jong\n",
      "Class - Messi\n",
      "Class - Messi\n",
      "Class - Messi\n",
      "Class - Gerard Pique\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "fc_barcelona_dict = {\"[0]\": \"De Jong\",\n",
    "                    \"[1]\": \"Messi\",\n",
    "                    \"[2]\": \"Gerard Pique\",}\n",
    "\n",
    "fc_barcelona_dict_n = {\"De_Jong\": \"De Jong\",\n",
    "                    \"Messi\": \"Messi\",\n",
    "                    \"Pique\": \"Gerard Pique\",}\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    player = fc_barcelona_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, player, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + fc_barcelona_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"Test/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
